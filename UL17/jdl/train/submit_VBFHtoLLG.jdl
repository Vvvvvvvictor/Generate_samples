Universe   = vanilla
Executable = run_and_transfer.sh

+ProjectName="cms.org.cern"

# custom args
NEVENT = 500
NTHREAD = 1
PROCNAME = VBFHToZG_ZToLL_TuneCP5_13TeV_madgraphMLM_pythia8

# EOSPATH = /eos/user/j/jiehan/Signal_madgraph_for_ML/VBFHToZG_ZToLL_TuneCP5_13TeV_madgraphMLM_pythia8/24UL17/
EOSPATH = root://eosuser.cern.ch//eos/user/j/jiehan/Signal_madgraph_for_ML/VBFHToZG_ZToLL_TuneCP5_13TeV_madgraphMLM_pythia8/24UL17/

# this dictates how often the config will change (i.e., how often different H, X masses are sampled)
NEVENTLUMIBLOCK = 10

# note: use different seeds in different H->2prong and H->WW/ZZ routines to avoid overlap in LHE events
BEGINSEED = 100000

Arguments = $(JOBNUM) $(NEVENT) $(NEVENTLUMIBLOCK) $(NTHREAD) $(PROCNAME) $(BEGINSEED) $(EOSPATH) $(Process) $(LHEPRODSCRIPT)

requirements = (OpSysAndVer =?= "CentOS7")
request_cpus = 16
request_memory = 2000
request_disk = 5000
use_x509userproxy = true

+JobFlavour = "tomorrow"

# Disable the job start and shadow start limits using environment variables
environment = "_CONDOR_MAX_JOB_RETRIES=99999999 _CONDOR_MAX_SHADOW_RETRIES=99999999"

# Prevent periodic remove
+PeriodicRemove = false

Log        = log/job.log_$(Cluster)
Output     = log/job.out_$(Cluster)-$(Process)
Error      = log/job.err_$(Cluster)-$(Process)

should_transfer_files   = YES
# transfer_input_files    = /afs/cern.ch/user/j/jiehan/private/HiggsZGammaAna/HiggsDNA/x509up_u152815
when_to_transfer_output = ON_EXIT_OR_EVICT
transfer_output_files   = dummy.cc

Queue JOBNUM from seq 1 1000 |
